\documentclass{article}%
\usepackage[T1]{fontenc}%
\usepackage[utf8]{inputenc}%
\usepackage{lmodern}%
\usepackage{textcomp}%
\usepackage{lastpage}%
\usepackage{geometry}%
\geometry{margin=0.7in}%
\usepackage{ragged2e}%
\usepackage{fancyhdr}%
%
\fancypagestyle{header}{%
\renewcommand{\headrulewidth}{0pt}%
\renewcommand{\footrulewidth}{0pt}%
\fancyhead{%
}%
\fancyfoot{%
}%
\fancyhead[L]{%
Page date: %
\linebreak%
2023{-}02{-}20%
}%
\fancyhead[C]{%
Georgia Institute of Technology%
}%
\fancyhead[R]{%
Page \thepage\ of \pageref{LastPage}%
}%
}%
%
\begin{document}%
\normalsize%
\pagestyle{header}%
\begin{minipage}{\textwidth}%
\centering%
\begin{Large}%
\textbf{HW3: Problem 1}%
\end{Large}%
\linebreak%
\begin{large}%
\textbf{Ian Dover}%
\end{large}%
\end{minipage}%
\section{Part 1}%
\label{sec:Part1}%
\subsection{Subsection A}%
\label{subsec:SubsectionA}%
Here is the calculation for the first outer product: {[}{[}0.43226352 0.25222353 0.48671532{]}\newline%
 {[}0.10984608 0.06409462 0.12368328{]}\newline%
 {[}0.42953904 0.25063381 0.48364764{]}{]}.\newline%
\newline%

%
\subsection{Subsection B}%
\label{subsec:SubsectionB}%
The first term for the Kruskal tensor is: {[}{[}7.53169304 8.36104576{]}\newline%
 {[}6.95335795 7.71902727{]}\newline%
 {[}6.47565559 7.1887227 {]}\newline%
 {[}4.39470396 4.87862699{]}\newline%
 {[}4.05724843 4.50401252{]}\newline%
 {[}3.77851157 4.19458254{]}\newline%
 {[}8.48045282 9.41427827{]}\newline%
 {[}7.82926544 8.69138536{]}\newline%
 {[}7.29138739 8.09427885{]}\newline%
 {[}1.91394119 2.12469491{]}\newline%
 {[}1.76697565 1.96154625{]}\newline%
 {[}1.64558273 1.82678614{]}\newline%
 {[}1.11677479 1.2397485 {]}\newline%
 {[}1.03102116 1.1445521 {]}\newline%
 {[}0.96018902 1.06592027{]}\newline%
 {[}2.15503843 2.39234059{]}\newline%
 {[}1.98955979 2.20864026{]}\newline%
 {[}1.85287512 2.05690455{]}\newline%
 {[}7.48422212 8.30834757{]}\newline%
 {[}6.90953217 7.67037562{]}\newline%
 {[}6.43484068 7.14341346{]}\newline%
 {[}4.36700493 4.84787787{]}\newline%
 {[}4.03167631 4.47562453{]}\newline%
 {[}3.75469628 4.16814484{]}\newline%
 {[}8.42700203 9.35494175{]}\newline%
 {[}7.77991897 8.6366051 {]}\newline%
 {[}7.24543108 8.04326205{]}{]}.\newline%
\newline%
%
The second term for the Kruskal tensor is: {[}{[}{-}2.55595915 {-}3.45550892{]}\newline%
 {[}{-}2.5740198  {-}3.47992588{]}\newline%
 {[}{-}0.99973259 {-}1.35158063{]}\newline%
 {[}{-}0.82170374 {-}1.11089593{]}\newline%
 {[}{-}0.82750998 {-}1.11874563{]}\newline%
 {[}{-}0.32139951 {-}0.43451354{]}\newline%
 {[}{-}1.61396023 {-}2.18198087{]}\newline%
 {[}{-}1.62536463 {-}2.19739896{]}\newline%
 {[}{-}0.63128107 {-}0.8534555 {]}\newline%
 {[} 4.33091368  5.85514478{]}\newline%
 {[} 4.36151634  5.8965178 {]}\newline%
 {[} 1.69398464  2.29016924{]}\newline%
 {[} 1.39232585  1.88234401{]}\newline%
 {[} 1.40216416  1.89564483{]}\newline%
 {[} 0.54459146  0.73625615{]}\newline%
 {[} 2.73475515  3.69723077{]}\newline%
 {[} 2.7540792   3.72335577{]}\newline%
 {[} 1.06966649  1.44612721{]}\newline%
 {[}{-}3.54806272 {-}4.79677556{]}\newline%
 {[}{-}3.57313368 {-}4.83067005{]}\newline%
 {[}{-}1.38778193 {-}1.87620089{]}\newline%
 {[}{-}1.14065063 {-}1.54209368{]}\newline%
 {[}{-}1.14871058 {-}1.55299026{]}\newline%
 {[}{-}0.44615173 {-}0.60317134{]}\newline%
 {[}{-}2.24042397 {-}3.02892361{]}\newline%
 {[}{-}2.25625502 {-}3.05032627{]}\newline%
 {[}{-}0.87631481 {-}1.18472693{]}{]}.\newline%
\newline%
%
Here is the calculation for the Kruskal tensor: {[}{[}4.97573389 4.90553684{]}\newline%
 {[}4.37933814 4.23910139{]}\newline%
 {[}5.475923   5.83714207{]}\newline%
 {[}3.57300022 3.76773106{]}\newline%
 {[}3.22973844 3.38526689{]}\newline%
 {[}3.45711206 3.760069  {]}\newline%
 {[}6.86649259 7.23229739{]}\newline%
 {[}6.20390081 6.4939864 {]}\newline%
 {[}6.66010632 7.24082335{]}\newline%
 {[}6.24485487 7.97983969{]}\newline%
 {[}6.12849198 7.85806405{]}\newline%
 {[}3.33956736 4.11695539{]}\newline%
 {[}2.50910064 3.12209251{]}\newline%
 {[}2.43318532 3.04019693{]}\newline%
 {[}1.50478047 1.80217642{]}\newline%
 {[}4.88979358 6.08957136{]}\newline%
 {[}4.74363899 5.93199602{]}\newline%
 {[}2.92254161 3.50303177{]}\newline%
 {[}3.9361594  3.51157201{]}\newline%
 {[}3.33639849 2.83970557{]}\newline%
 {[}5.04705875 5.26721256{]}\newline%
 {[}3.22635429 3.3057842 {]}\newline%
 {[}2.88296573 2.92263427{]}\newline%
 {[}3.30854455 3.5649735 {]}\newline%
 {[}6.18657807 6.32601814{]}\newline%
 {[}5.52366395 5.58627883{]}\newline%
 {[}6.36911627 6.85853512{]}{]}.\newline%
\newline%

%
\section{Part 2}%
\label{sec:Part2}%
Here is the calculation for the Tucker tensor: {[}{[}{[}{[} 5.10100643  5.80186261{]}\newline%
   {[} 4.99129859  5.53890968{]}\newline%
   {[} 4.80561947  5.4454022 {]}{]}\newline%
\newline%
  {[}{[} 3.48145003  3.44117511{]}\newline%
   {[} 2.84300047  3.59675864{]}\newline%
   {[} 3.19627907  3.27594982{]}{]}\newline%
\newline%
  {[}{[} 8.4494077   5.746398  {]}\newline%
   {[} 4.06876905  7.8071309 {]}\newline%
   {[} 7.33749349  5.73753646{]}{]}{]}\newline%
\newline%
\newline%
 {[}{[}{[} 3.33961221  6.57606924{]}\newline%
   {[} 6.5368703   0.73014512{]}\newline%
   {[} 3.63097401  5.34938374{]}{]}\newline%
\newline%
  {[}{[} 2.38667868  3.61945962{]}\newline%
   {[} 3.38294471  1.82517912{]}\newline%
   {[} 2.40381302  3.1553465 {]}{]}\newline%
\newline%
  {[}{[} 6.33187165  4.42028174{]}\newline%
   {[} 2.79251954 11.09517187{]}\newline%
   {[} 5.4605745   5.16818593{]}{]}{]}\newline%
\newline%
\newline%
 {[}{[}{[} 3.30654779  6.59527835{]}\newline%
   {[} 6.57138663  0.6350008 {]}\newline%
   {[} 3.60973992  5.35058505{]}{]}\newline%
\newline%
  {[}{[} 2.3663087   3.62510679{]}\newline%
   {[} 3.39564197  1.79103195{]}\newline%
   {[} 2.38946098  3.15478383{]}{]}\newline%
\newline%
  {[}{[} 6.2934687   4.39649616{]}\newline%
   {[} 2.7687788  11.16696751{]}\newline%
   {[} 5.42644706  5.15987497{]}{]}{]}{]}.\newline%
\newline%

%
\section{Part 3}%
\label{sec:Part3}%
In CP decomposition, the tensor is decomposed into a series of rank{-}1 tensors whereas in Tucker decompositon,\newline%
        the tensor is decomposed into a core tensor and factor matrices. CP decomposition is capable of representing any non{-}negative tensor\newline%
        to any desired accuracy; however, Tucker decomposition is only capable of representing tensors that have a lower rank structure.\newline%
        Finally, CP decomposition is less computationally intensive than Tucker decomposition.%
The mean{-}square error for Tucker decomposition is: 2.6217621054926816.\newline%
\newline%
%
The mean{-}square error for CP decomposition is: 3.19421561560853\newline%
\newline%

%
\end{document}